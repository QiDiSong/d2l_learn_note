{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer and block\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(20, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0188,  0.1511, -0.1886, -0.1540, -0.0092, -0.1905,  0.0692,  0.0419,\n",
       "         -0.1051,  0.1184],\n",
       "        [ 0.0919,  0.0533, -0.2360, -0.2985,  0.0369, -0.2856, -0.0738, -0.0828,\n",
       "         -0.2076,  0.1451]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 20)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.out(F.relu(self.hidden(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0926,  0.0705, -0.2660, -0.1389, -0.0780, -0.2122, -0.0457,  0.1269,\n",
       "          -0.0186,  0.1293],\n",
       "         [-0.0849,  0.1036, -0.1554, -0.1827, -0.0031, -0.1593, -0.0359,  0.0300,\n",
       "           0.0347,  0.1464]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.1987, -0.0509,  0.1977,  0.2436,  0.1256,  0.0195, -0.1403, -0.3043,\n",
       "           0.3677,  0.0285],\n",
       "         [ 0.0323, -0.0304,  0.0330,  0.1555,  0.2481,  0.1104,  0.0269, -0.2569,\n",
       "           0.1228, -0.0268]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.1987, -0.0509,  0.1977,  0.2436,  0.1256,  0.0195, -0.1403, -0.3043,\n",
       "           0.3677,  0.0285],\n",
       "         [ 0.0323, -0.0304,  0.0330,  0.1555,  0.2481,  0.1104,  0.0269, -0.2569,\n",
       "           0.1228, -0.0268]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 20)\n",
    "mlp = MLP()\n",
    "net(x), mlp(x), mlp.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1254, -0.0653, -0.0624,  0.1660,  0.1033, -0.0889,  0.2056,  0.0043,\n",
       "          0.0832,  0.0389, -0.1497,  0.2734, -0.0480,  0.0406, -0.0152,  0.0106,\n",
       "          0.1540, -0.1328, -0.1839, -0.1363],\n",
       "        [ 0.0539,  0.0008,  0.0719,  0.0299,  0.0498, -0.0855,  0.1297,  0.0440,\n",
       "         -0.0139,  0.0371, -0.1556,  0.1745, -0.2012,  0.0545, -0.0793,  0.0204,\n",
       "          0.0206,  0.0042, -0.1819, -0.0934]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args) -> None:\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            self._modules[block] = block\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for block in self._modules.values():\n",
    "            x = block(x)\n",
    "        return x\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 20))\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0257,  0.0657,  0.1901, -0.1300,  0.1691, -0.0320, -0.0717, -0.1572,\n",
       "         -0.1928, -0.1286,  0.1095,  0.0991,  0.2782,  0.1584, -0.1364,  0.2207,\n",
       "         -0.0403, -0.0764, -0.1334,  0.3239],\n",
       "        [ 0.0130,  0.0713,  0.2061, -0.1274,  0.1729, -0.0142, -0.0856, -0.1506,\n",
       "         -0.2004, -0.1227,  0.1151,  0.0928,  0.2610,  0.1746, -0.1339,  0.2353,\n",
       "         -0.0464, -0.0812, -0.1155,  0.2954]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(20, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(self.net(x))\n",
    "\n",
    "chimera = nn.Sequential(\n",
    "    NestMLP(),\n",
    "    nn.Linear(16, 20),\n",
    "    # 可以很灵活的嵌套使用\n",
    ")\n",
    "chimera(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2825],\n",
       "        [-0.2501]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter Management\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "x = torch.rand(size=(2, 4))\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.3477, -0.3291, -0.1199,  0.1273],\n",
       "                      [-0.4685, -0.1462, -0.3261, -0.4817],\n",
       "                      [ 0.2077, -0.3973,  0.0481, -0.4569],\n",
       "                      [ 0.2406, -0.2041,  0.2241,  0.4448],\n",
       "                      [-0.1539,  0.3636, -0.1811,  0.2011],\n",
       "                      [-0.1051,  0.1996, -0.2217,  0.1891],\n",
       "                      [-0.1465,  0.4027,  0.4486, -0.2097],\n",
       "                      [-0.4343,  0.1832,  0.1637, -0.0583]])),\n",
       "             ('bias',\n",
       "              tensor([-0.0094, -0.2667, -0.4531, -0.0297, -0.4095, -0.3470, -0.1216,  0.1620]))])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[1].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.1475,  0.2821, -0.1007, -0.0862,  0.0621,  0.1009,  0.0137,  0.0990]])),\n",
       "             ('bias', tensor([-0.2662]))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[2].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.2662], requires_grad=True)\n",
      "tensor([-0.2662])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(type(net[2].bias))\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)\n",
    "print(net[2].bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('weight', torch.Size([8, 4])), ('bias', torch.Size([8]))]\n",
      "[('0.weight', torch.Size([8, 4])), ('0.bias', torch.Size([8])), ('2.weight', torch.Size([1, 8])), ('2.bias', torch.Size([1]))]\n"
     ]
    }
   ],
   "source": [
    "print([(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "print([(name, param.shape) for name, param in net.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.3477, -0.3291, -0.1199,  0.1273],\n",
       "                      [-0.4685, -0.1462, -0.3261, -0.4817],\n",
       "                      [ 0.2077, -0.3973,  0.0481, -0.4569],\n",
       "                      [ 0.2406, -0.2041,  0.2241,  0.4448],\n",
       "                      [-0.1539,  0.3636, -0.1811,  0.2011],\n",
       "                      [-0.1051,  0.1996, -0.2217,  0.1891],\n",
       "                      [-0.1465,  0.4027,  0.4486, -0.2097],\n",
       "                      [-0.4343,  0.1832,  0.1637, -0.0583]])),\n",
       "             ('0.bias',\n",
       "              tensor([-0.0094, -0.2667, -0.4531, -0.0297, -0.4095, -0.3470, -0.1216,  0.1620])),\n",
       "             ('2.weight',\n",
       "              tensor([[-0.1475,  0.2821, -0.1007, -0.0862,  0.0621,  0.1009,  0.0137,  0.0990]])),\n",
       "             ('2.bias', tensor([-0.2662]))])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1475,  0.2821, -0.1007, -0.0862,  0.0621,  0.1009,  0.0137,  0.0990]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 4), nn.ReLU())\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'module {i}', block1())\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3039],\n",
       "        [-0.3039]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "rgnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (module 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (module 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (module 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (module 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (module 0): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (module 1): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (module 2): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (module 3): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (3): ReLU()\n",
      ")\n",
      "Linear(in_features=4, out_features=8, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(rgnet[0])\n",
    "print(rgnet[0][0])\n",
    "print(rgnet[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0064,  0.0070, -0.0032,  0.0026],\n",
       "         [-0.0087, -0.0071,  0.0022, -0.0138],\n",
       "         [-0.0129,  0.0016, -0.0145, -0.0087],\n",
       "         [ 0.0100, -0.0131,  0.0007,  0.0015],\n",
       "         [ 0.0224, -0.0061, -0.0101, -0.0188],\n",
       "         [ 0.0062,  0.0058, -0.0091, -0.0037],\n",
       "         [-0.0017, -0.0142,  0.0033,  0.0101],\n",
       "         [ 0.0047,  0.0309,  0.0094,  0.0003]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data, net[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([2., 2., 2., 2., 2., 2., 2., 2.]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 2)\n",
    "\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data, net[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.bias, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6578, -0.1700,  0.0170,  0.6516],\n",
      "        [-0.6848,  0.5857,  0.3264, -0.0347],\n",
      "        [-0.6460,  0.5526,  0.6986, -0.4984],\n",
      "        [ 0.0716, -0.5996,  0.3527, -0.5074],\n",
      "        [ 0.0692, -0.2321, -0.3740, -0.5290],\n",
      "        [ 0.4265, -0.5074,  0.4755,  0.3182],\n",
      "        [-0.0331, -0.0484,  0.1610, -0.6345],\n",
      "        [ 0.4860,  0.5008, -0.2605, -0.1428]])\n",
      "tensor([42.])\n"
     ]
    }
   ],
   "source": [
    "net[0].apply(xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data)\n",
    "print(net[2].bias.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 7.2166, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 5.0048],\n",
      "        [0.0000, 0.0000, 9.5269, 0.0000],\n",
      "        [0.0000, 6.7699, 0.0000, 0.0000],\n",
      "        [0.0000, 7.0299, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 9.1215, 6.1191]])\n",
      "tensor([[-0.0000, -0.0000,  0.0000, -9.4322],\n",
      "        [ 0.0000, -8.6026,  7.2166,  0.0000],\n",
      "        [-0.0000, -0.0000, -9.0070,  5.0048],\n",
      "        [-0.0000,  0.0000,  9.5269, -0.0000],\n",
      "        [ 0.0000,  6.7699, -0.0000,  0.0000],\n",
      "        [ 0.0000,  7.0299, -7.2648,  0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  9.1215,  6.1191]])\n",
      "Init weight torch.Size([1, 8])\n",
      "tensor([[0.0000, 5.3375, 5.3902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[-7.3344,  5.3375,  5.3902, -0.0000,  0.0000, -5.3590,  0.0000, -9.5614]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\n",
    "            'Init', \n",
    "            *[(name, param.shape) for name, param in m.named_parameters()][0]\n",
    "        )\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        # m.weight.data = torch.where(m.weight.data >= 5, m.weight.data, 0)\n",
    "        print(torch.where(m.weight.data >= 5, m.weight.data, 0))\n",
    "        m.weight.data *= m.weight.data.abs() >= 5 \n",
    "        print(m.weight.data)\n",
    "\n",
    "net.apply(my_init)\n",
    "# net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4059],\n",
       "        [-0.4110]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参数绑定\n",
    "share_layer = nn.Linear(8, 8)\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 8),\n",
    "    nn.ReLU(),\n",
    "    share_layer,\n",
    "    nn.ReLU(),\n",
    "    share_layer,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net[2].weight.data == net[4].weight.data)\n",
    "net[2].weight.data[0, 0] = 100\n",
    "net[2].weight.data == net[4].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
